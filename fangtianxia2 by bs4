import requests
from bs4 import BeautifulSoup
import pandas as pd

url = 'http://land.fang.com/market/440100__3______1_0_{}.html'

def get_url(url):
    list_total = []
    for y in range(1,2):    #  range(1,35)
        news_url = url.format(y)
        res = requests.get(news_url)
        soup = BeautifulSoup(res.text, 'html.parser') 
        [s.extract() for s in soup('span')] #删除span节点
        for i in range(0,4):   #    range(0,30)
            try:
                result = {}
                result['标题名称'] = soup.select('h3 a')[i]['title']
                result['网址'] =  'http://land.fang.com' + soup.select('h3 a')[i]['href']
                result['成交状态'] = soup.select('tbody tr td')[6*i+1].text
                result['推出时间'] = soup.select('tbody tr td')[6*i].text
                result['所属地区'] = soup.select('tbody tr td')[6*i+3].text.strip('广东省>广州市>')
                date_url = result['网址']
                res1 = requests.get(date_url)
                soup1 = BeautifulSoup(res1.text, 'html.parser') 
                result['地块编号'] = soup1.select('.gray2')[0].text.strip('地块编号：')
                result['总面积'] = soup1.select('.red01')[1].text+'平方米'
                result['位置'] = soup1.select('td')[13].text.strip('位置：')
                result['规划用途'] = soup1.select('td')[15].text.strip('规划用途：')
                result['竞得方'] = soup1.select('td')[17].text.strip('竞得方：')
                result['成交价'] = soup1.select('td')[23].text.strip('成交价：')
                result['成交日期'] = soup1.select('td')[20].text.strip('成交日期：')
                result['土地公告'] = soup1.select('td a')[3]['href']
                print(result)   # 测试
                list_total.append(result)
                print(list_total)  # 测试
                print('正在下载：' + result['标题名称'] )
            except:
                continue
    df = pd.DataFrame(list_total)
    df.to_csv('fangtianxia.csv')

get_url(url)
